"""
Demo Script for Vision-Based Step-to-Image Mapping (Bonus Task)
Tests the vision mapper with example data and generates sample outputs
"""

import json
from pathlib import Path
from vision_mapper import VisionMapper, create_mapping_report
from PIL import Image, ImageDraw

def create_sample_images(output_dir: str = "./sample_images"):
    """
    Create sample UI images for testing vision mapping.
    """
    Path(output_dir).mkdir(exist_ok=True)
    
    # Create sample images
    images = {
        'account_settings.png': {
            'size': (1000, 200),
            'elements': [
                {'text': 'Account Settings', 'pos': (850, 50), 'size': (150, 40)}
            ]
        },
        'payment_page.png': {
            'size': (1000, 600),
            'elements': [
                {'text': 'Payment Methods', 'pos': (200, 300), 'size': (180, 35)},
                {'text': 'Billing History', 'pos': (200, 350), 'size': (180, 35)}
            ]
        },
        'edit_payment.png': {
            'size': (1000, 700),
            'elements': [
                {'text': 'Edit', 'pos': (600, 400), 'size': (80, 35)},
                {'text': 'Card Number', 'pos': (400, 350), 'size': (250, 30)},
                {'text': 'Save Changes', 'pos': (500, 500), 'size': (120, 40)}
            ]
        }
    }
    
    for filename, config in images.items():
        # Create white background
        img = Image.new('RGB', config['size'], color='white')
        draw = ImageDraw.Draw(img)
        
        # Draw elements
        for element in config['elements']:
            x, y = element['pos']
            w, h = element['size']
            
            # Draw button/element box
            draw.rectangle([x, y, x+w, y+h], outline='blue', width=2, fill='lightblue')
            
            # Draw text
            text_x = x + 10
            text_y = y + h//2 - 5
            draw.text((text_x, text_y), element['text'], fill='black')
        
        # Save image
        img.save(Path(output_dir) / filename)
        print(f"‚úÖ Created {filename}")
    
    return output_dir

def demo_vision_mapping():
    """
    Demonstrate the vision mapping functionality with examples.
    """
    print("\n" + "="*70)
    print("VISION-BASED STEP-TO-IMAGE MAPPING DEMO")
    print("="*70 + "\n")
    
    # Example steps (would be generated by GPT in real scenario)
    steps = [
        "Click on Account Settings in the top right corner",
        "Navigate to Payment Methods from the sidebar",
        "Click the Edit button next to your current payment method",
        "Enter your new credit card number in the Card Number field",
        "Click Save Changes to update your payment method"
    ]
    
    print("Generated Steps:")
    for i, step in enumerate(steps, 1):
        print(f"{i}. {step}")
    print()
    
    # Example visual items (from JSON simulation data)
    visual_items = [
        {
            "sequenceNumber": 1,
            "fileId": "account_settings.png",
            "hotspots": [
                {
                    "type": "button",
                    "text": "Account Settings",
                    "coordinates": {"x": 850, "y": 50, "width": 150, "height": 40}
                }
            ]
        },
        {
            "sequenceNumber": 2,
            "fileId": "payment_page.png",
            "hotspots": [
                {
                    "type": "menu_item",
                    "text": "Payment Methods",
                    "coordinates": {"x": 200, "y": 300, "width": 180, "height": 35}
                },
                {
                    "type": "menu_item",
                    "text": "Billing History",
                    "coordinates": {"x": 200, "y": 350, "width": 180, "height": 35}
                }
            ]
        },
        {
            "sequenceNumber": 3,
            "fileId": "edit_payment.png",
            "hotspots": [
                {
                    "type": "button",
                    "text": "Edit",
                    "coordinates": {"x": 600, "y": 400, "width": 80, "height": 35}
                },
                {
                    "type": "input_field",
                    "text": "Card Number",
                    "coordinates": {"x": 400, "y": 350, "width": 250, "height": 30}
                },
                {
                    "type": "button",
                    "text": "Save Changes",
                    "coordinates": {"x": 500, "y": 500, "width": 120, "height": 40}
                }
            ]
        }
    ]
    
    # Create sample images
    print("Creating sample UI images...")
    image_dir = create_sample_images()
    print()
    
    # Initialize vision mapper
    mapper = VisionMapper()
    
    # Perform mapping
    print("Performing vision mapping...")
    mappings = mapper.map_steps_to_images(steps, visual_items)
    
    print("\n" + "="*70)
    print("MAPPING RESULTS")
    print("="*70 + "\n")
    
    for mapping in mappings:
        print(f"Step {mapping['step_index'] + 1}: {mapping['step']}")
        if mapping['file_id']:
            print(f"  ‚úÖ Mapped to: {mapping['file_id']}")
            print(f"     Hotspot: {mapping['hotspot'].get('text', 'N/A')}")
            print(f"     Type: {mapping['hotspot'].get('type', 'N/A')}")
            print(f"     Relevance Score: {mapping['relevance_score']:.2f}")
        else:
            print(f"  ‚ùå No mapping found")
        print()
    
    # Process with full pipeline (including image highlighting)
    print("="*70)
    print("PROCESSING WITH IMAGE HIGHLIGHTING")
    print("="*70 + "\n")
    
    result = mapper.process_simulation_with_vision(steps, visual_items, image_dir)
    
    print(f"Total Steps: {result['total_steps']}")
    print(f"Mapped Steps: {result['mapped_steps']}")
    print(f"Mapping Rate: {result['mapped_steps']/result['total_steps']*100:.1f}%\n")
    
    # Create highlighted images
    output_dir = Path("./highlighted_images")
    output_dir.mkdir(exist_ok=True)
    
    for mapping in result['mappings']:
        if mapping.get('highlighted_image'):
            output_path = output_dir / f"step_{mapping['step_index'] + 1}_{mapping['file_id']}"
            mapping['highlighted_image'].convert('RGB').save(output_path)
            print(f"‚úÖ Saved highlighted image: {output_path}")
    
    # Generate and save report
    report = create_mapping_report(result)
    print("\n" + report)
    
    # Save report to file
    with open("vision_mapping_report.txt", "w") as f:
        f.write(report)
    print("\n‚úÖ Report saved to: vision_mapping_report.txt")
    
    # Save mapping data as JSON
    # Convert PIL Images to strings for JSON serialization
    json_result = {
        'total_steps': result['total_steps'],
        'mapped_steps': result['mapped_steps'],
        'mappings': []
    }
    
    for mapping in result['mappings']:
        json_mapping = {
            'step_index': mapping['step_index'],
            'step': mapping['step'],
            'file_id': mapping.get('file_id'),
            'relevance_score': mapping.get('relevance_score', 0.0),
            'hotspot_text': mapping.get('hotspot_text', 'N/A'),
            'hotspot_type': mapping.get('hotspot_type', 'N/A'),
            'image_found': mapping.get('image_found', False)
        }
        json_result['mappings'].append(json_mapping)
    
    with open("vision_mapping_results.json", "w") as f:
        json.dump(json_result, f, indent=2)
    print("‚úÖ Results saved to: vision_mapping_results.json")
    
    print("\n" + "="*70)
    print("DEMO COMPLETE!")
    print("="*70)
    print("\nGenerated files:")
    print("  ‚Ä¢ sample_images/ - Sample UI screenshots")
    print("  ‚Ä¢ highlighted_images/ - Images with highlighted elements")
    print("  ‚Ä¢ vision_mapping_report.txt - Text report")
    print("  ‚Ä¢ vision_mapping_results.json - JSON results")
    print("\nYou can now use these images in your presentation!")

def test_keyword_extraction():
    """
    Test the keyword extraction functionality.
    """
    print("\n" + "="*70)
    print("TESTING KEYWORD EXTRACTION")
    print("="*70 + "\n")
    
    mapper = VisionMapper()
    
    test_steps = [
        "Click the Submit button to save your changes",
        "Enter your email address in the Email field",
        "Navigate to Account Settings from the menu",
        "Select Payment Methods from the dropdown",
        "Update your billing information and click Save"
    ]
    
    for step in test_steps:
        keywords = mapper.extract_keywords_from_step(step)
        print(f"Step: {step}")
        print(f"  Actions: {keywords['actions']}")
        print(f"  Elements: {keywords['elements']}")
        print(f"  Targets: {keywords['targets']}")
        print()

def test_relevance_scoring():
    """
    Test the relevance scoring functionality.
    """
    print("\n" + "="*70)
    print("TESTING RELEVANCE SCORING")
    print("="*70 + "\n")
    
    mapper = VisionMapper()
    
    step = "Click the Save Changes button to update your payment method"
    
    hotspots = [
        {"type": "button", "text": "Save Changes"},
        {"type": "button", "text": "Cancel"},
        {"type": "input_field", "text": "Card Number"},
        {"type": "menu_item", "text": "Payment Methods"}
    ]
    
    print(f"Step: {step}\n")
    
    for hotspot in hotspots:
        score = mapper.calculate_relevance_score(step, hotspot)
        print(f"Hotspot: {hotspot['text']} ({hotspot['type']})")
        print(f"  Relevance Score: {score:.2f}")
        print()

if __name__ == "__main__":
    # Run all demos
    test_keyword_extraction()
    test_relevance_scoring()
    demo_vision_mapping()
    
    print("\nüéâ All demos completed successfully!")
    print("You can now use vision_mapper.py in your Streamlit app.")
